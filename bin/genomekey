#!/usr/bin/env python
import argparse
import os
import sys
import subprocess

from flask import Flask

from cosmos import add_execution_args, Cosmos
from genomekey.workflows.dna_seq.main import run_dna_seq
from genomekey import settings as s, library_path
from genomekey.util.misc import assert_references_exist
from cosmos.web.gemon.views import bprint as gemon_bprint


opj = os.path.join

flask_app = Flask('genomekey', template_folder=os.path.join(library_path, 'web/templates'))

flask_app.secret_key = '\x16\x89\xf5-\tK`\xf5FY.\xb9\x9c\xb4qX\xfdm\x19\xbd\xdd\xef\xa9\xe2'
flask_app.register_blueprint(gemon_bprint, url_prefix='/gemon')
cosmos = Cosmos(s['gk']['database_url'], default_drm=s['gk']['default_drm'], flask_app=flask_app)


def gunicorn():
    flask_app = cosmos.flask_app
    return flask_app


def do_growl(msg, hostname=os.environ.get('SSH_CLIENT', '').split(' ')[0]):
    from cosmos.util import growl

    growl.send(msg, hostname=hostname)


def text_on_finish(ex):
    from cosmos import signal_execution_status_change, ExecutionStatus

    @signal_execution_status_change.connect
    def sig(ex):
        msg = "%s %s" % (ex, ex.status)
        if ex.status in [ExecutionStatus.successful, ExecutionStatus.failed]:
            text_message(msg)
            ex.log.info('Sent a text message')

    def text_message(message):
        from twilio.rest import TwilioRestClient

        account = s['gk']['twilio_account']
        token = s['gk']['twilio_token']
        phone_number = "+1%s" % s['gk']['phone_number']
        client = TwilioRestClient(account, token)

        message = client.messages.create(to=phone_number, from_='+15203086165', body=message)


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--ipdb', '-d',
                        help='Launch ipdb on exception',
                        action='store_true')

    sps = parser.add_subparsers(title="Commands", metavar="<command>")

    sp = sps.add_parser('resetdb', help=cosmos.resetdb.__doc__)
    sp.set_defaults(func=cosmos.resetdb)

    sp = sps.add_parser('initdb', help=cosmos.initdb.__doc__)
    sp.set_defaults(func=cosmos.initdb)

    sp = sps.add_parser('shell', help=cosmos.shell.__doc__)
    sp.set_defaults(func=cosmos.shell)

    sp = sps.add_parser('runweb', help=cosmos.runweb.__doc__)
    sp.add_argument('-p', '--port', type=int, default=5000, help='port to bind the server to')
    # sp.add_argument('-H', '--host', default='localhost', help='host to bind the server to')
    sp.set_defaults(func=lambda port: cosmos.runweb('0.0.0.0', port))


    def add_execution_args2(sp):
        add_execution_args(sp)
        sp.add_argument('-m', '--comments', help="adds comments to the execution's info field")
        sp.add_argument('-drm', '--default_drm', help="overrides config value")
        sp.add_argument('-s', '--sms', help='send an sms after an execution finishes with its status',
                        action='store_true')
        sp.add_argument('-g', '--growl', help='sends growl notifications on execution status changes',
                        action='store_true')


    sp = sps.add_parser('dna_seq', help=run_dna_seq.__doc__)
    sp.set_defaults(func=run_dna_seq)
    sp.add_argument('input_path', help='file with inputs')
    sp.add_argument('--use_s3', '-s3', default=False,
                    help='upload/download all output files to this s3 bucket.  Removes the need'
                         'for a shared filesystem')
    sp.add_argument('--target_bed', '-t', required=True)  # default to whole genome target bed?
    add_execution_args2(sp)

    sp = sps.add_parser('growl', help='send a message over growl')
    sp.add_argument('msg', help='message to send')
    sp.add_argument('-H', '--hostname')
    sp.set_defaults(func=do_growl)

    args = parser.parse_args()
    kwargs = dict(args._get_kwargs())
    f = kwargs.pop('func')

    workflow_fxns = dict(run_dna_seq='DNA-Seq')

    if f.__name__ in workflow_fxns.keys():
        assert_references_exist()
        d = {n: kwargs.pop(n) for n in ['name', 'restart', 'skip_confirm', 'max_cpus', 'max_attempts', 'comments']}
        comments = d.pop('comments')
        workflow_type = workflow_fxns[f.__name__]

        def get_output_dir():
            root_output_dir = opj(s['gk']['analysis_output'], workflow_type)
            os.system('mkdir -p %s' % root_output_dir)
            return opj(root_output_dir, d['name'])

        d['output_dir'] = get_output_dir()

        ex = cosmos.start(**d)

        ex.info['workflow_type'] = workflow_type
        ex.info['comments'] = comments
        kwargs['execution'] = ex

        ex.use_s3 = kwargs.pop('use_s3', False)
        if ex.use_s3:
            ex.use_s3 = os.path.join(ex.use_s3, d['name'])

            if d['restart']:
                ex.log.info('Deleting S3 Objects since restart==True')
                from cosmos.util.helpers import confirm

                if not d['skip_confirm']:
                    confirm("Are you sure you want to delete %s?" % ex.use_s3)
                cmd = 'aws s3 rm %s --recursive --only-show-errors' % ex.use_s3
                ex.log.info('run: ' + cmd)
                subprocess.check_call(cmd, shell=True)

        # required for gof3r, which doesn't check ~/.aws/config files
        # gof3r is used to stream input files from s3 for some tools
        from genomekey.aws.config import set_env_aws_credentials

        set_env_aws_credentials()


    # Send growl on fail
    if kwargs.pop('growl', False):
        from cosmos import signal_execution_status_change, ExecutionStatus

        @signal_execution_status_change.connect
        def growl_signal(execution):
            if execution.status not in [ExecutionStatus.running, ExecutionStatus.killed]:
                do_growl('%s %s' % (execution, execution.status))

    # Send a text on execution end
    if kwargs.pop('sms', False):
        text_on_finish(ex)


    # overwrite default_drm in conf?
    default_drm = kwargs.pop('default_drm', None)
    if default_drm:
        cosmos.default_drm = default_drm

    # launch ipdb on exception if --ipdb
    if kwargs.pop('ipdb', False):
        import ipdb

        with ipdb.launch_ipdb_on_exception():
            try:
                f(**kwargs)
            except TypeError:
                import inspect

                args_needed = inspect.getargspec(f).args
                raise
    else:
        f(**kwargs)

    if 'execution' in kwargs:
        if ex.use_s3 and ex.successful:
            ex.log.info('Data output to: %s' % ex.use_s3)

        exit_code = 0 if kwargs['execution'].successful else 1
        sys.exit(exit_code)


if __name__ == '__main__':
    parse_args()